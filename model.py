# -*- coding: utf-8 -*-
"""Copy of Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18uusR2DQBe8PuB3NeRZN87_-4gBkzOAD
"""

from google.colab import drive
drive.mount('/content/drive')

cd drive/MyDrive/SMAI/smai-24-age-prediction/content/faces_dataset

import numpy as np
import pandas as pd
from glob import glob
from os.path import join
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm

import torch
import torch.nn as nn
import torchvision
from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize
import torch.optim as optim

from tqdm import tqdm

from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomRotation, CenterCrop, ColorJitter, RandomResizedCrop, GaussianBlur,RandomGrayscale,RandomPerspective
import pandas as pd
from PIL import Image
from os.path import join

class AgeDataset(torch.utils.data.Dataset):

    def __init__(self, data_path, annot_path, train=True):
        super(AgeDataset, self).__init__()

        self.annot_path = annot_path
        self.data_path = data_path
        self.train = train

        self.ann = pd.read_csv(annot_path)
        self.files = self.ann['file_id']
        if train:
            self.ages = self.ann['age']
        self.transform = self._transform(224, train)

    @staticmethod
    def _convert_image_to_rgb(image):
        return image.convert("RGB")

    def _transform(self, n_px, train):
        transforms = [
            Resize(n_px),
            self._convert_image_to_rgb,
            ToTensor(),
            Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]
        if train:
            augments = [
               RandomHorizontalFlip(),
                RandomRotation(10),  # Rotate +/- 10 degrees
               ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
               RandomResizedCrop(n_px, scale=(0.8, 1.0)),
                RandomPerspective(distortion_scale=0.1, p=0.5, interpolation=3),# Crop between 80-100% of image, then resize
              RandomGrayscale(p=0.2),
               GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5))  # Apply Gaussian Blur with a kernel size between 5 and 9
            ]
            transforms = augments + transforms  # Add augments before the standard transforms

        return Compose(transforms)

    def read_img(self, file_name):
        im_path = join(self.data_path, file_name)
        img = Image.open(im_path)
        img = self.transform(img)
        return img

    def __getitem__(self, index):
        file_name = self.files[index]
        img = self.read_img(file_name)
        if self.train:
            age = self.ages[index]
            return img, age
        else:
            return img

    def __len__(self):
        return len(self.files)

train_path = 'train'
train_ann = 'train.csv'

import pandas as pd

data_path = 'train.csv'
full_data = pd.read_csv(data_path)

mean_age = full_data['age'].mean()
std_dev_age = full_data['age'].std()

print("Mean of age:", mean_age)
print("Standard deviation of age:", std_dev_age)

"""# **Data Exploration**

Noise Present in the data(Non facial images)
"""

non_face_images = ['image_17664.jpg','image_10983.jpg','image_7761.jpg', 'image_7206.jpg','image_683.jpg','image_7206.jpg','image_528.jpg','image_965.jpg','image_1360.jpg','image_2535.jpg','image_13782.jpg','image_14229.jpg','image_16079.jpg']

import pandas as pd

# Load the data
data_path = 'train.csv'
full_data = pd.read_csv(data_path)

# Define age bins and labels for the categorization
bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 116]
labels = ['0-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', '101-120']

# Use cut to categorize the ages
full_data['AgeGroup'] = pd.cut(full_data['age'], bins=bins, labels=labels, right=False)

# Calculate the distribution
age_distribution = full_data['AgeGroup'].value_counts().reindex(labels)

# Print the distribution
print(age_distribution)

# Calculate the total sum of the counts
total_count = age_distribution.sum()
print(f"Total: {total_count}")

"""# Observations:
Model may not perform well for ages greater than 60 as they are underrepresented. Might have to add similar images(by generating images with GANs or Autoencoders with some noise)
"""



test_path = 'test'
test_ann = 'submission.csv'
test_dataset = AgeDataset(test_path, test_ann, train=False)

from sklearn.model_selection import train_test_split

train_data, val_data = train_test_split(full_data, test_size=0.1, stratify=full_data['age'], random_state=42)

train_data.to_csv('train_split.csv', index=False)
val_data.to_csv('val_split.csv', index=False)


train_dataset = AgeDataset('train', 'train_split.csv', train=True)


val_dataset = AgeDataset('train', 'val_split.csv', train=True)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)

pip install --upgrade timm

import timm
model = timm.create_model('efficientnet_b4', pretrained=True)
num_ftrs = model.classifier.in_features
model.classifier = nn.Linear(num_ftrs, 1)



from torchvision import models
from torchvision.models.efficientnet import EfficientNet_B7_Weights
weights = EfficientNet_B7_Weights.DEFAULT  # Use DEFAULT weights; change as necessary
model = models.efficientnet_b7(weights=weights)

# Replace the classifier layer for your specific task
num_ftrs = model.classifier[1].in_features  # Access the in_features of the classifier's linear layer
model.classifier[1] = nn.Linear(num_ftrs, 1)

from torchvision import models
model = models.resnet34(pretrained=True)
num_ftrs = model.fc.in_features
model.fc = torch.nn.Linear(num_ftrs, 1)



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
criterion = nn.SmoothL1Loss(reduction='sum',beta=25)
optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, amsgrad=True)

optimizer = optim.Adam(model.parameters(), lr=0.002)





import torch
import copy
from tqdm import tqdm

def train_model(train_loader, val_loader, model, criterion, optimizer, device, num_epochs=30, patience=5, checkpoint_path='model_age_prediction_best.pth'):
    model.to(device)
    early_stopping_counter = 0
    best_val_loss = float('inf')
    train_losses = []
    val_losses = []
    val_mean_losses = []
    val_std_losses = []

    best_model_wts = copy.deepcopy(model.state_dict())  # Initialize with the initial model weights

    for epoch in range(num_epochs):
        model.train()
        running_train_loss = 0.0
        for inputs, ages in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}, Training'):
            inputs, ages = inputs.to(device), ages.to(device).float().view(-1, 1)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, ages)
            loss.backward()
            optimizer.step()
            running_train_loss += loss.item()

        train_loss = running_train_loss / len(train_loader)
        train_losses.append(train_loss)

        # Validation phase
        model.eval()
        val_loss, val_mean, val_std = evaluate(val_loader, model, criterion, device)
        val_losses.append(val_loss)
        val_mean_losses.append(val_mean)
        val_std_losses.append(val_std)
        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Mean: {val_mean:.4f}, Val Std: {val_std:.4f}')

        # Early Stopping
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_wts = copy.deepcopy(model.state_dict())
            torch.save(best_model_wts, checkpoint_path)
            early_stopping_counter = 0
        else:
            early_stopping_counter += 1
            if early_stopping_counter >= patience:
                print("Early stopping triggered.")
                break

    # Load the best model weights
    model.load_state_dict(best_model_wts)

    return train_losses, val_losses, val_mean_losses, val_std_losses, model

def evaluate(loader, model, criterion, device):
    total_loss = 0.0
    all_losses = []
    with torch.no_grad():
        for inputs, ages in loader:
            inputs, ages = inputs.to(device), ages.to(device).float().view(-1, 1)
            outputs = model(inputs)
            loss = criterion(outputs, ages)
            total_loss += loss.item()
            all_losses.append(loss.item())

    average_loss = total_loss / len(loader)
    mean_losses = torch.mean(torch.tensor(all_losses))
    std_losses = torch.std(torch.tensor(all_losses))
    return average_loss, mean_losses.item(), std_losses.item()

train_losses, val_losses, test_predictions_stats, trained_model = train_model(
    train_loader, val_loader, test_loader, model, criterion, optimizer, device, num_epochs=50, patience=5
)

criterion = nn.MSELoss(reduction='sum')
optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, amsgrad=True)



# Save the trained model
torch.save(model.state_dict(), 'model_age_prediction_resnet18_fullauggr_best.pth')

@torch.no_grad()
def predict(loader, model):
    model.eval()  # Ensure the model is in evaluation mode
    predictions = []
    for inputs in loader:
        inputs = inputs.to(device)
        outputs = model(inputs)
        # Convert predictions to integers
        int_preds = outputs
        predictions.extend(int_preds.cpu().numpy().flatten())  # Flatten and convert to numpy array
    return predictions

preds = predict(test_loader, model)

submit = pd.read_csv('submission.csv')
submit['age'] = preds
submit.head()

submit.to_csv('model_age_prediction_resnet34_best.csv',index=False)

from torchvision import models
import torch.nn as nn

model = models.resnet34(pretrained=False)
num_ftrs = model.fc.in_features  # Get the number of input features to fc layer
model.fc = torch.nn.Linear(num_ftrs, 1)

model.load_state_dict(torch.load('model_age_prediction_best_smat_loss.pth'))

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Move model to the chosen device
model.to(device)



"""# Ensemble Methods."""

predicted_ages = pd.read_csv('model_age_prediction_resnet34_best.csv')
predicted_values = predicted_ages['age'] # Replace 'predicted_ages.csv' with your actual file path
#Load the second set of predictions
predicted_ages_2 = pd.read_csv('model_age_prediction_resnet34_fullauggr_best.csv')  # Adjust the file path
predicted_values_2 = predicted_ages_2['age']
predicted_ages_3 = pd.read_csv('model_age_prediction_resnet34_auggr_best_5.47.csv')  # Adjust the file path
predicted_values_3 = predicted_ages_3['age']
predicted_ages_4 = pd.read_csv('model_age_prediction_resnet34_bestuggr_best (2).csv')  # Adjust the file path
predicted_values_4 = predicted_ages_4['age']
predicted_ages_5 = pd.read_csv('model_age_prediction_resnet50_aug_best_5.57.csv')  # Adjust the file path
predicted_values_5 = predicted_ages_5['age']
predicted_ages_6 = pd.read_csv('model_age_prediction_resnet101_best.csv')  # Adjust the file path
predicted_values_6 = predicted_ages_6['age']


# Calculate the average of the predictions from both models
average_predictions = (predicted_values+ predicted_values_2+predicted_values_3+ predicted_values_4 + predicted_values_5+ predicted_values_6) / 6

submit = pd.read_csv('submission.csv')
submit['age'] = average_predictions
submit.head()

submit.to_csv('enesemble_submision6',index=False)